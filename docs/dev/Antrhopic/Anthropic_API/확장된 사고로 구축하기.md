# 확장된 사고로 구축하기

> 확장된 사고는 Claude에게 복잡한 작업을 위한 향상된 추론 능력을 제공하며, 최종 답변을 제공하기 전에 단계별 사고 과정에 대한 다양한 수준의 투명성을 제공합니다.

---

## 지원되는 모델

확장된 사고는 다음 모델에서 지원됩니다:

- Claude Sonnet 4.5 (`claude-sonnet-4-5-20250929`)
- Claude Sonnet 4 (`claude-sonnet-4-20250514`)
- Claude Sonnet 3.7 (`claude-3-7-sonnet-20250219`)
- Claude Haiku 4.5 (`claude-haiku-4-5-20251001`)
- Claude Opus 4.1 (`claude-opus-4-1-20250805`)
- Claude Opus 4 (`claude-opus-4-20250514`)
### 주의사항

- API 동작은 Claude Sonnet 3.7과 Claude 4 모델 간에 다르지만, API 형태는 정확히 동일하게 유지됩니다.
- 자세한 정보는 [모델 버전 간 사고의 차이점](#모델-버전-간-사고의-차이점) 섹션을 참조하세요.

---

## 확장된 사고 작동 방식

확장된 사고가 켜져 있을 때, Claude는 내부 추론을 출력하는 `thinking` 콘텐츠 블록을 생성합니다. Claude는 최종 응답을 작성하기 전에 이 추론에서 얻은 통찰력을 통합합니다.

API 응답에는 `thinking` 콘텐츠 블록이 포함되고, 그 다음에 `text` 콘텐츠 블록이 포함됩니다.

### 기본 응답 형식 예시
```json
{
  "content": [
    {
      "type": "thinking",
      "thinking": "Let me analyze this step by step...",
      "signature": "WaUjzkypQ2mUEVM36O2TxuC06KN8xyfbJwyem2dw3URve/op91XWHOEBLLqIOMfFG/UvLEczmEsUjavL...."
    },
    {
      "type": "text",
      "text": "Based on my analysis..."
    }
  ]
}
```

확장된 사고의 응답 형식에 대한 자세한 정보는 [Messages API 참조](/ko/api/messages)를 참조하세요.

---

## 확장된 사고 사용 방법

### Shell (cURL)
```bash
curl https://api.anthropic.com/v1/messages \
     --header "x-api-key: $ANTHROPIC_API_KEY" \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --data \
'{
    "model": "claude-sonnet-4-5",
    "max_tokens": 16000,
    "thinking": {
        "type": "enabled",
        "budget_tokens": 10000
    },
    "messages": [
        {
            "role": "user",
            "content": "Are there an infinite number of prime numbers such that n mod 4 == 3?"
        }
    ]
}'
```
### Python

```python
import anthropic
client = anthropic.Anthropic()
response = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    messages=[{
        "role": "user",
        "content": "Are there an infinite number of prime numbers such that n mod 4 == 3?"
    }]
)
# 응답에는 요약된 사고 블록과 텍스트 블록이 포함됩니다
for block in response.content:
    if block.type == "thinking":
        print(f"\nThinking summary: {block.thinking}")
    elif block.type == "text":
        print(f"\nResponse: {block.text}")
```
### TypeScript

```typescript
import Anthropic from '@anthropic-ai/sdk';
const client = new Anthropic();
const response = await client.messages.create({
  model: "claude-sonnet-4-5",
  max_tokens: 16000,
  thinking: {
    type: "enabled",
    budget_tokens: 10000
  },
  messages: [{
    role: "user",
    content: "Are there an infinite number of prime numbers such that n mod 4 == 3?"
  }]
});
// 응답에는 요약된 사고 블록과 텍스트 블록이 포함됩니다
for (const block of response.content) {
  if (block.type === "thinking") {
    console.log(`\nThinking summary: ${block.thinking}`);
  } else if (block.type === "text") {
    console.log(`\nResponse: ${block.text}`);
  }
}
```
### Java

```java
import com.anthropic.client.AnthropicClient;
import com.anthropic.client.okhttp.AnthropicOkHttpClient;
import com.anthropic.models.beta.messages.*;
import com.anthropic.models.beta.messages.MessageCreateParams;
import com.anthropic.models.messages.*;
public class SimpleThinkingExample {
    public static void main(String[] args) {
        AnthropicClient client = AnthropicOkHttpClient.fromEnv();
        BetaMessage response = client.beta().messages().create(
                MessageCreateParams.builder()
                        .model(Model.CLAUDE_OPUS_4_0)
                        .maxTokens(16000)
                        .thinking(BetaThinkingConfigEnabled.builder().budgetTokens(10000).build())
                        .addUserMessage("Are there an infinite number of prime numbers such that n mod 4 == 3?")
                        .build()
        );
        System.out.println(response);
    }
}
```

### 설정 방법
확장된 사고를 켜려면:

1. `thinking` 객체를 추가합니다
2. `type` 매개변수를 `enabled`로 설정합니다
3. `budget_tokens`를 확장된 사고를 위한 지정된 토큰 예산으로 설정합니다

### budget_tokens 매개변수
`budget_tokens` 매개변수는 Claude가 내부 추론 과정에 사용할 수 있는 최대 토큰 수를 결정합니다.

**Claude 4 모델에서:**
- 이 제한은 전체 사고 토큰에 적용됩니다
- 요약된 출력에는 적용되지 않습니다

**주의사항:**
- 더 큰 예산은 복잡한 문제에 대한 더 철저한 분석을 가능하게 합니다
- Claude는 특히 32k 이상의 범위에서 할당된 전체 예산을 사용하지 않을 수 있습니다
- `budget_tokens`는 `max_tokens`보다 작은 값으로 설정되어야 합니다
- 도구와 함께 인터리브된 사고를 사용할 때는 토큰 제한이 전체 컨텍스트 창(200k 토큰)이 됩니다

---

## 요약된 사고

확장된 사고가 활성화된 상태에서 Claude 4 모델의 Messages API는 Claude의 전체 사고 과정의 요약을 반환합니다. 요약된 사고는 오용을 방지하면서 확장된 사고의 완전한 지능적 이점을 제공합니다.

### 요약된 사고의 주요 특성

- **청구**: 원래 요청에서 생성된 전체 사고 토큰에 대해 요금이 부과되며, 요약 토큰에 대해서는 부과되지 않습니다
- **표시 vs 청구**: 청구된 출력 토큰 수는 응답에서 보는 토큰 수와 **일치하지 않습니다**
- **상세함**: 사고 출력의 처음 몇 줄은 더 자세하며, 프롬프트 엔지니어링 목적에 특히 도움이 되는 상세한 추론을 제공합니다
- **개선 중**: Anthropic이 확장된 사고 기능을 개선하려고 노력함에 따라 요약 동작은 변경될 수 있습니다
- **지연시간**: 요약은 최소한의 추가 지연 시간으로 Claude의 사고 과정의 핵심 아이디어를 보존합니다
- **스트리밍 호환성**: 요약으로 스트리밍 가능한 사용자 경험과 Claude Sonnet 3.7에서 Claude 4 모델로의 쉬운 마이그레이션이 가능합니다
- **모델 처리**: 요약은 요청에서 대상으로 하는 모델과 다른 모델에 의해 처리됩니다. 사고 모델은 요약된 출력을 보지 않습니다

### Claude Sonnet 3.7 참고사항

Claude Sonnet 3.7은 계속해서 전체 사고 출력을 반환합니다. Claude 4 모델의 전체 사고 출력에 액세스해야 하는 드문 경우에는 [영업팀에 문의](mailto:sales@anthropic.com)하세요.

---

## 스트리밍 사고

서버 전송 이벤트(SSE)를 사용하여 확장된 사고 응답을 스트리밍할 수 있습니다.

확장된 사고에 대해 스트리밍이 활성화되면 `thinking_delta` 이벤트를 통해 사고 콘텐츠를 받습니다.

Messages API를 통한 스트리밍에 대한 자세한 문서는 [스트리밍 메시지](/ko/docs/build-with-claude/streaming)를 참조하세요.

### Shell (cURL)
```bash
curl https://api.anthropic.com/v1/messages \
     --header "x-api-key: $ANTHROPIC_API_KEY" \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --data \
'{
    "model": "claude-sonnet-4-5",
    "max_tokens": 16000,
    "stream": true,
    "thinking": {
        "type": "enabled",
        "budget_tokens": 10000
    },
    "messages": [
        {
            "role": "user",
            "content": "What is 27 * 453?"
        }
    ]
}'
```
### Python

```python
import anthropic
client = anthropic.Anthropic()
with client.messages.stream(
    model="claude-sonnet-4-5",
    max_tokens=16000,
    thinking={"type": "enabled", "budget_tokens": 10000},
    messages=[{"role": "user", "content": "What is 27 * 453?"}],
) as stream:
    thinking_started = False
    response_started = False
    for event in stream:
        if event.type == "content_block_start":
            print(f"\nStarting {event.content_block.type} block...")
            thinking_started = False
            response_started = False
        elif event.type == "content_block_delta":
            if event.delta.type == "thinking_delta":
                if not thinking_started:
                    print("Thinking: ", end="", flush=True)
                    thinking_started = True
                print(event.delta.thinking, end="", flush=True)
            elif event.delta.type == "text_delta":
                if not response_started:
                    print("Response: ", end="", flush=True)
                    response_started = True
                print(event.delta.text, end="", flush=True)
        elif event.type == "content_block_stop":
            print("\nBlock complete.")
```
### TypeScript

```typescript
import Anthropic from '@anthropic-ai/sdk';
const client = new Anthropic();
const stream = await client.messages.stream({
  model: "claude-sonnet-4-5",
  max_tokens: 16000,
  thinking: {
    type: "enabled",
    budget_tokens: 10000
  },
  messages: [{
    role: "user",
    content: "What is 27 * 453?"
  }]
});
let thinkingStarted = false;
let responseStarted = false;
for await (const event of stream) {
  if (event.type === 'content_block_start') {
    console.log(`\nStarting ${event.content_block.type} block...`);
    thinkingStarted = false;
    responseStarted = false;
  } else if (event.type === 'content_block_delta') {
    if (event.delta.type === 'thinking_delta') {
      if (!thinkingStarted) {
        process.stdout.write('Thinking: ');
        thinkingStarted = true;
      }
      process.stdout.write(event.delta.thinking);
    } else if (event.delta.type === 'text_delta') {
      if (!responseStarted) {
        process.stdout.write('Response: ');
        responseStarted = true;
      }
      process.stdout.write(event.delta.text);
    }
  } else if (event.type === 'content_block_stop') {
    console.log('\nBlock complete.');
  }
}
```
### Java

```java
import com.anthropic.client.AnthropicClient;
import com.anthropic.client.okhttp.AnthropicOkHttpClient;
import com.anthropic.core.http.StreamResponse;
import com.anthropic.models.beta.messages.MessageCreateParams;
import com.anthropic.models.beta.messages.BetaRawMessageStreamEvent;
import com.anthropic.models.beta.messages.BetaThinkingConfigEnabled;
import com.anthropic.models.messages.Model;
public class SimpleThinkingStreamingExample {
    private static boolean thinkingStarted = false;
    private static boolean responseStarted = false;
    
    public static void main(String[] args) {
        AnthropicClient client = AnthropicOkHttpClient.fromEnv();
        MessageCreateParams createParams = MessageCreateParams.builder()
                .model(Model.CLAUDE_OPUS_4_0)
                .maxTokens(16000)
                .thinking(BetaThinkingConfigEnabled.builder().budgetTokens(10000).build())
                .addUserMessage("What is 27 * 453?")
                .build();
        try (StreamResponse<BetaRawMessageStreamEvent> streamResponse =
                     client.beta().messages().createStreaming(createParams)) {
            streamResponse.stream()
                    .forEach(event -> {
                        if (event.isContentBlockStart()) {
                            System.out.printf("\nStarting %s block...%n",
                                event.asContentBlockStart()._type());
                            thinkingStarted = false;
                            responseStarted = false;
                        } else if (event.isContentBlockDelta()) {
                            var delta = event.asContentBlockDelta().delta();
                            if (delta.isBetaThinking()) {
                                if (!thinkingStarted) {
                                    System.out.print("Thinking: ");
                                    thinkingStarted = true;
                                }
                                System.out.print(delta.asBetaThinking().thinking());
                                System.out.flush();
                            } else if (delta.isBetaText()) {
                                if (!responseStarted) {
                                    System.out.print("Response: ");
                                    responseStarted = true;
                                }
                                System.out.print(delta.asBetaText().text());
                                System.out.flush();
                            }
                        } else if (event.isContentBlockStop()) {
                            System.out.println("\nBlock complete.");
                        }
                    });
        }
    }
}
```
### 스트리밍 출력 예시
```json
event: message_start
data: {"type": "message_start", "message": {"id": "msg_01...", "type": "message", "role": "assistant", "content": [], "model": "claude-sonnet-4-5", "stop_reason": null, "stop_sequence": null}}

event: content_block_start
data: {"type": "content_block_start", "index": 0, "content_block": {"type": "thinking", "thinking": ""}}

event: content_block_delta
data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "Let me solve this step by step:\n\n1. First break down 27 * 453"}}

event: content_block_delta
data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\n2. 453 = 400 + 50 + 3"}}


event: content_block_delta
data: {"type": "content_block_delta", "index": 0, "delta": {"type": "signature_delta", "signature": "EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds..."}}

event: content_block_stop
data: {"type": "content_block_stop", "index": 0}

event: content_block_start
data: {"type": "content_block_start", "index": 1, "content_block": {"type": "text", "text": ""}}

event: content_block_delta
data: {"type": "content_block_delta", "index": 1, "delta": {"type": "text_delta", "text": "27 * 453 = 12,231"}}


event: content_block_stop
data: {"type": "content_block_stop", "index": 1}

event: message_delta
data: {"type": "message_delta", "delta": {"stop_reason": "end_turn", "stop_sequence": null}}

event: message_stop
data: {"type": "message_stop"}
```

### 스트리밍 시 참고사항

사고가 활성화된 스트리밍을 사용할 때 텍스트가 때때로 다음과 같은 패턴으로 도착합니다:

- 더 작은 토큰별 전달과 번갈아 가며 더 큰 청크로 도착
- 이는 특히 사고 콘텐츠에서 예상되는 동작입니다

이 동작이 나타나는 이유:
- 스트리밍 시스템은 최적의 성능을 위해 콘텐츠를 배치로 처리해야 함
- 스트리밍 이벤트 간에 지연이 발생할 수 있음
- Anthropic은 이 경험을 지속적으로 개선 중

---

## 도구 사용과 함께하는 확장된 사고

확장된 사고는 도구 사용과 함께 사용할 수 있어 Claude가 도구 선택 및 결과 처리를 통해 추론할 수 있습니다.
### 제한사항

#### 1. 도구 선택 제한

사고와 함께하는 도구 사용은 다음만 지원합니다:
- `tool_choice: {"type": "auto"}` (기본값)
- `tool_choice: {"type": "none"}`

**지원하지 않음:**
- `tool_choice: {"type": "any"}` - 오류 발생
- `tool_choice: {"type": "tool", "name": "..."}` - 오류 발생

이러한 옵션들은 도구 사용을 강제하므로 확장된 사고와 호환되지 않습니다.
#### 2. 사고 블록 보존

도구 사용 중에는 마지막 어시스턴트 메시지에 대해 `thinking` 블록을 API에 다시 전달해야 합니다.

**규칙:**
- 완전하고 수정되지 않은 블록을 API에 포함시킵니다
- 추론 연속성을 유지합니다

---

## 도구 결과와 함께 사고 블록 전달하기

### 실제 예시

#### Python

```python
weather_tool = {
    "name": "get_weather",
    "description": "Get current weather for a location",
    "input_schema": {
        "type": "object",
        "properties": {
            "location": {"type": "string"}
        },
        "required": ["location"]
    }
}
# 첫 번째 요청 - Claude가 사고와 도구 요청으로 응답합니다
response = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    tools=[weather_tool],
    messages=[
        {"role": "user", "content": "What's the weather in Paris?"}
    ]
)
```
#### TypeScript

```typescript
const weatherTool = {
  name: "get_weather",
  description: "Get current weather for a location",
  input_schema: {
    type: "object",
    properties: {
      location: { type: "string" }
    },
    required: ["location"]
  }
};
// 첫 번째 요청 - Claude가 사고와 도구 요청으로 응답합니다
const response = await client.messages.create({
  model: "claude-sonnet-4-5",
  max_tokens: 16000,
  thinking: {
    type: "enabled",
    budget_tokens: 10000
  },
  tools: [weatherTool],
  messages: [
    { role: "user", content: "What's the weather in Paris?" }
  ]
});
```
#### Java

```java
import java.util.List;
import java.util.Map;
import com.anthropic.client.AnthropicClient;
import com.anthropic.client.okhttp.AnthropicOkHttpClient;
import com.anthropic.core.JsonValue;
import com.anthropic.models.beta.messages.BetaMessage;
import com.anthropic.models.beta.messages.MessageCreateParams;
import com.anthropic.models.beta.messages.BetaThinkingConfigEnabled;
import com.anthropic.models.beta.messages.BetaTool;
import com.anthropic.models.beta.messages.BetaTool.InputSchema;
import com.anthropic.models.messages.Model;
public class ThinkingWithToolsExample {
    public static void main(String[] args) {
        AnthropicClient client = AnthropicOkHttpClient.fromEnv();
        InputSchema schema = InputSchema.builder()
                .properties(JsonValue.from(Map.of(
                        "location", Map.of("type", "string")
                )))
                .putAdditionalProperty("required", JsonValue.from(List.of("location")))
                .build();
        BetaTool weatherTool = BetaTool.builder()
                .name("get_weather")
                .description("Get current weather for a location")
                .inputSchema(schema)
                .build();
        BetaMessage response = client.beta().messages().create(
                MessageCreateParams.builder()
                        .model(Model.CLAUDE_OPUS_4_0)
                        .maxTokens(16000)
                        .thinking(BetaThinkingConfigEnabled.builder().budgetTokens(10000).build())
                        .addTool(weatherTool)
                        .addUserMessage("What's the weather in Paris?")
                        .build()
        );
        System.out.println(response);
    }
}
```
### API 응답
```json
{
    "content": [
        {
            "type": "thinking",
            "thinking": "The user wants to know the current weather in Paris. I have access to a function `get_weather`...",
            "signature": "BDaL4VrbR2Oj0hO4XpJxT28J5TILnCrrUXoKiiNBZW9P+nr8XSj1zuZzAl4egiCCpQNvfyUuFFJP5CncdYZEQPPmLxYsNrcs...."
        },
        {
            "type": "text",
            "text": "I can help you get the current weather information for Paris. Let me check that for you"
        },
        {
            "type": "tool_use",
            "id": "toolu_01CswdEQBMshySk6Y9DFKrfq",
            "name": "get_weather",
            "input": {
                "location": "Paris"
            }
        }
    ]
}
```
### 도구 결과 처리

#### Python

```python
# 사고 블록과 도구 사용 블록 추출
thinking_block = next((block for block in response.content
                      if block.type == 'thinking'), None)
tool_use_block = next((block for block in response.content
                      if block.type == 'tool_use'), None)
# 실제 날씨 API 호출 (예시)
weather_data = {"temperature": 88}
# 두 번째 요청 - 사고 블록과 도구 결과 포함
continuation = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    tools=[weather_tool],
    messages=[
        {"role": "user", "content": "What's the weather in Paris?"},
        # 사고_블록과 도구_사용_블록 모두 포함됩니다
        # 포함되지 않으면 오류 발생
        {"role": "assistant", "content": [thinking_block, tool_use_block]},
        {"role": "user", "content": [{
            "type": "tool_result",
            "tool_use_id": tool_use_block.id,
            "content": f"Current temperature: {weather_data['temperature']}°F"
        }]}
    ]
)
```
#### TypeScript

```typescript
// 사고 블록과 도구 사용 블록 추출
const thinkingBlock = response.content.find(block =>
  block.type === 'thinking');
const toolUseBlock = response.content.find(block =>
  block.type === 'tool_use');
// 실제 날씨 API 호출 (예시)
const weatherData = { temperature: 88 };
// 두 번째 요청 - 사고 블록과 도구 결과 포함
const continuation = await client.messages.create({
  model: "claude-sonnet-4-5",
  max_tokens: 16000,
  thinking: {
    type: "enabled",
    budget_tokens: 10000
  },
  tools: [weatherTool],
  messages: [
    { role: "user", content: "What's the weather in Paris?" },
    // 사고_블록과 도구_사용_블록 모두 포함됩니다
    // 포함되지 않으면 오류 발생
    { role: "assistant", content: [thinkingBlock, toolUseBlock] },
    { role: "user", content: [{
      type: "tool_result",
      tool_use_id: toolUseBlock.id,
      content: `Current temperature: ${weatherData.temperature}°F`
    }]}
  ]
});
```
### API 응답 (도구 결과 후)

```json
{
    "content": [
        {
            "type": "text",
            "text": "Currently in Paris, the temperature is 88°F (31°C)"
        }
    ]
}
```

---

## 사고 블록 보존 원칙
도구 사용 중에는 `thinking` 블록을 API에 다시 전달해야 하며, 완전하고 수정되지 않은 블록을 API에 다시 포함시켜야 합니다.

### 왜 사고 블록 보존이 중요한가?
1. **추론 연속성**: 사고 블록은 도구 요청으로 이어진 Claude의 단계별 추론을 캡처합니다
2. **컨텍스트 유지**: 도구 결과가 API 구조에서 사용자 메시지로 나타나지만, 연속적인 추론 흐름의 일부입니다
3. **여러 턴 호출**: 여러 API 호출에 걸쳐 이 개념적 흐름이 유지됩니다

### 선택적 포함

이전 `assistant` 역할 턴에서 `thinking` 블록을 생략할 수 있지만, 다중 턴 대화에서는 항상 모든 사고 블록을 API에 다시 전달하는 것을 권장합니다.

**API의 자동 처리:**
- 제공된 사고 블록을 자동으로 필터링합니다
- 모델의 추론을 보존하는 데 필요한 관련 사고 블록을 사용